{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Adds padding to an vector / image\n",
    "## 1 for vectors, 2 for matrices, 3 for images, 4 for batch of images\n",
    "\n",
    "def padding(X, pad = 1, dims = 3, const = 0):\n",
    "    if (dims == 1): return np.pad(X, ((pad, pad)), 'constant', constant_values = (const,const) ) \n",
    "    if (dims == 2): return np.pad(X, ((pad, pad), (pad, pad)), 'constant', constant_values = (const,const) ) \n",
    "    if (dims == 3): return np.pad(X, ((pad, pad), (pad, pad), (0,0)), 'constant', constant_values = (const,const) )    \n",
    "    if (dims == 4): return np.pad(X, ((0,0), (pad, pad), (pad, pad), (0,0)), 'constant', constant_values = (const,const) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convolution of a slice with (W)eights, return output Z\n",
    "def conv_slice(slice, W, b):\n",
    "    conv = np.multiply(slice, W)\n",
    "    Z = np.sum(conv) + float(b)\n",
    "    return Z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Forward propagation with modes conv, maxpool or avepool\n",
    "def forward(X, W, b, pad, stride, f, mode='conv'):\n",
    "    \n",
    "    # Shape of input batch\n",
    "    (m, Xh, Xw, Xc) = np.shape(X)\n",
    "\n",
    "    # Shape of weights is filter size x input channels x #filters\n",
    "    if(mode == 'conv'): (f, f, Xc, Zc) = np.shape(W)\n",
    "    else: Zc = Xc\n",
    "   \n",
    "    # Shape of output volume\n",
    "    Zh = int((Xh + 2*pad - f) / stride + 1)\n",
    "    Zw = int((Xw + 2*pad - f) / stride + 1)\n",
    "\n",
    "    # Initialize output, batch_size, out_height, out_width, #filters\n",
    "    Z = np.zeros((m, Zh, Zw, Zc))\n",
    "    \n",
    "    # Pad the input, with #paddings, 4 dim, 0-padding\n",
    "    X_pad = padding(X, pad, 4, 0)\n",
    "    \n",
    "    for i in range(m):                               \n",
    "        Xi = X_pad[i]\n",
    "        for h in range(Zh):    \n",
    "            for w in range(Zw):\n",
    "                for c in range(Zc):\n",
    "                    \n",
    "                    # Find the current slice\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = h*stride + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = w*stride +f\n",
    "\n",
    "                    if(mode == 'conv'):\n",
    "                        Xi_slice = Xi[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                        Z[i, h, w, c] = conv_slice(Xi_slice, W[:,:,:,c], b[0,0,0,c])\n",
    "                        cache = (X, W, b, pad, stride)\n",
    "                    if(mode == 'maxpool'):\n",
    "                        Xi_slice = Xi[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        Z[i, h, w, c] = np.max(Xi_slice)\n",
    "                        cache = (X, f, stride)\n",
    "                    if(mode == 'avepool'):\n",
    "                        Xi_slice = Xi[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        Z[i, h, w, c] = np.mean(Xi_slice)\n",
    "                        cache = (X, f, stride)\n",
    "                                        \n",
    "    assert(Z.shape == (m, Zh, Zw, Zc))\n",
    "    \n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(dZ, cache):\n",
    "\n",
    "    (X, W, b, pad, stride) = cache\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, Xh, Xw, Xc) = np.shape(X)\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, Xc, Zc) = np.shape(W)\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, Zh, Zw, Zc) = np.shape(dZ)\n",
    "    \n",
    "    # Initialize dX, dW, db\n",
    "    dX = np.zeros((m, Xh, Xw, Xc))                           \n",
    "    dW = np.zeros((f, f, Xc, Zc))\n",
    "    db = np.zeros((1, 1, 1, Zc))\n",
    "\n",
    "    # Pad X and dX\n",
    "    X_pad = padding(X, pad, 4, 0)\n",
    "    dX_pad = padding(dX, pad, 4, 0)\n",
    "    \n",
    "    for i in range(m):     \n",
    "        Xi = X_pad[i,:,:,:]\n",
    "        dXi = dX_pad[i,:,:,:]\n",
    "        \n",
    "        for h in range(Zh):                   # loop over vertical axis of the output volume\n",
    "            for w in range(Zw):               # loop over horizontal axis of the output volume\n",
    "                for c in range(Zc):           # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = stride * h\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = stride * w\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    Xi_slice = X_pad[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
    "                    dXi[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += Xi_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "\n",
    "        # Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
    "        dX[i, :, :, :] = dXi[pad:-pad, pad:-pad, :]\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dX.shape == (m, Xh, Xw, Xc))\n",
    "    \n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask of maximum value of x\n",
    "def max_mask(x):\n",
    "    return (x == np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spread value dz to a shape\n",
    "def distribute_value(dz, shape):\n",
    "    (h, w) = shape\n",
    "    average = dz/(h*w)\n",
    "    return np.full(shape,average)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = 'max'):\n",
    "    \n",
    "    X, f, stride = cache\n",
    "\n",
    "    m, Xh, Xw, Xc = np.shape(X)\n",
    "    m, Zh, Zw, Zc = np.shape(dA)\n",
    "    dX = np.zeros(np.shape(X))\n",
    "\n",
    "    for i in range(m):\n",
    "        Xi = X[i,:,:,:]\n",
    "        \n",
    "        for h in range(Zh):                   # loop on the vertical axis\n",
    "            for w in range(Zw):               # loop on the horizontal axis\n",
    "                for c in range(Zc):           # loop over the channels (depth)\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" (â‰ˆ4 lines)\n",
    "                    vert_start = stride * h\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = stride * w\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Compute the backward propagation in both modes.\n",
    "                    if mode == \"max\":\n",
    "                        \n",
    "                        Xi_slice = Xi[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        mask = max_mask(Xi_slice)\n",
    "                        dX[i, vert_start: vert_end, horiz_start: horiz_end, c] += mask * dA[i, h, w, c]\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        dX[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(dA[i, h, w, c], (f,f))\n",
    "                        \n",
    "    ### END CODE ###\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dX.shape == X.shape)\n",
    "    \n",
    "    return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "mean of dA =  0.145713902729\n",
      "dA_prev[1,1] =  [[ 0.          0.        ]\n",
      " [ 5.05844394 -1.68282702]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "mode = average\n",
      "mean of dA =  0.145713902729\n",
      "dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]\n",
      " [ 1.26461098 -0.25749373]\n",
      " [ 1.17975636 -0.53624893]]\n"
     ]
    }
   ],
   "source": [
    "def test_pool_backward():\n",
    "    np.random.seed(1)\n",
    "    X = np.random.randn(5, 5, 3, 2)\n",
    "    stride = 1\n",
    "    f = 2\n",
    "    #forward(X, W, b, pad, stride, f, mode='conv'):\n",
    "    A, cache = forward(X, None, None, 0, str1, 2, mode='maxpool')\n",
    "    dA = np.random.randn(5, 4, 2, 2)\n",
    "\n",
    "    dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
    "    print(\"mode = max\")\n",
    "    print('mean of dA = ', np.mean(dA))\n",
    "    print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
    "    print()\n",
    "    dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
    "    print(\"mode = average\")\n",
    "    print('mean of dA = ', np.mean(dA))\n",
    "    print('dA_prev[1,1] = ', dA_prev[1,1]) \n",
    "test_pool_backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = 0.0489952035289\n",
      "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
      "  5.18531798  8.75898442]\n",
      "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n",
      "mode = max\n",
      "A = [[[[ 1.74481176  0.86540763  1.13376944]]]\n",
      "\n",
      "\n",
      " [[[ 1.13162939  1.51981682  2.18557541]]]]\n",
      "\n",
      "mode = average\n",
      "A = [[[[ 0.02105773 -0.20328806 -0.40389855]]]\n",
      "\n",
      "\n",
      " [[[-0.22154621  0.51716526  0.48155844]]]]\n",
      "dA_mean = 1.45243777754\n",
      "dW_mean = 1.72699145831\n",
      "db_mean = 7.83923256462\n"
     ]
    }
   ],
   "source": [
    "def test_forward():\n",
    "    np.random.seed(1)\n",
    "    # 10 images of 4x4, RGB\n",
    "    X = np.random.randn(10,4,4,3)\n",
    "    # 8 filters of 2x2, RGB\n",
    "    W = np.random.randn(2,2,3,8)\n",
    "    # 8 biases for our 8 filters\n",
    "    b = np.random.randn(1,1,1,8)\n",
    "    pad = 2\n",
    "    stride = 2\n",
    "\n",
    "    # forward(X, W, b, pad, stride, pool_size, mode='conv')\n",
    "    Z, cache_conv = forward(X, W, b, pad, stride, None)\n",
    "    print(\"Z's mean =\", np.mean(Z))\n",
    "    print(\"Z[3,2,1] =\", Z[3,2,1])\n",
    "    print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])\n",
    "\n",
    "    np.random.seed(1)\n",
    "    X = np.random.randn(2, 4, 4, 3)\n",
    "    stride = 2\n",
    "    f = 3\n",
    "\n",
    "    # forward(X, W, b, pad, stride, pool_size, mode='conv')\n",
    "    A, cache = forward(X, None, None, 0, stride, f, mode='maxpool')\n",
    "    print(\"mode = max\")\n",
    "    print(\"A =\", A)\n",
    "    print()\n",
    "    A, cache = forward(X, None, None, 0, stride, f, mode='avepool')\n",
    "    print(\"mode = average\")\n",
    "    print(\"A =\", A)\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    dA, dW, db = backward(Z, cache_conv)\n",
    "    print(\"dA_mean =\", np.mean(dA))\n",
    "    print(\"dW_mean =\", np.mean(dW))\n",
    "    print(\"db_mean =\", np.mean(db))\n",
    "    \n",
    "test_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "## 0*0 + 1*1 + 2*0.5 + 4*0.25 + 1 = 4.0\n",
    "def test_conv_slice():\n",
    "    slice = [[0,1],[2,4]]\n",
    "    weights = [[0,1],[0.5,0.25]]\n",
    "    bias = 1\n",
    "    print (np.shape(slice))\n",
    "    print (conv_slice(slice, weights, bias))\n",
    "    \n",
    "test_conv_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_padding():\n",
    "    batch = [[[[0,4,8],[1,5,9]],[[2,6,0],[3,7,1]]],[[[0,4,8],[1,5,9]],[[2,6,0],[3,7,1]]]]\n",
    "    image = [[[0,4,8],[1,5,9]],[[2,6,10],[3,7,11]]]\n",
    "    matrix = np.matrix('1 2 3; 4 5 6')\n",
    "    vector = [0,1,2,3]\n",
    "\n",
    "    padded_vector = padding(vector, 1, 1, 0)\n",
    "    print (\"Vector\")\n",
    "    print (vector)\n",
    "    print (np.shape(vector))\n",
    "    print (padded_vector)\n",
    "    print (np.shape(padded_vector))\n",
    "    print ()\n",
    "\n",
    "    padded_matrix = padding(matrix, 1, 2, 0)\n",
    "    print (\"Matrix\")\n",
    "    print (matrix)\n",
    "    print (np.shape(matrix))\n",
    "    print (padded_matrix)\n",
    "    print (np.shape(padded_matrix))\n",
    "    print ()\n",
    "\n",
    "    padded_image = padding(image, 1, 3, 0)\n",
    "    print (\"Padded image and shape\")\n",
    "    print (np.shape(image))\n",
    "    print (np.shape(padded_image))\n",
    "    print ()\n",
    "\n",
    "    padded_batch = padding(batch, 1, 4, 0)\n",
    "    print (\"Padded batch and shape\")\n",
    "    print (np.shape(batch))\n",
    "    print (np.shape(padded_batch))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
